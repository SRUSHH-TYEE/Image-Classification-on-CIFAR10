{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8266b526",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de84340c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fccc54",
   "metadata": {},
   "source": [
    "### Vectorizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16987f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "X_train_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3905b273",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b0e8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train_flat)\n",
    "X_test_standardized = scaler.fit_transform(X_test_flat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bee46e",
   "metadata": {},
   "source": [
    "### Using inbuilt KNN algorithm from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d61f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time \n",
    "\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "neigh.fit(X_train_standardized, y_train)\n",
    "\n",
    "knn_prediction = neigh.predict(X_test_standardized)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7516d831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken by inbuilt KNN implementation:  30.15088200569153 seconds\n",
      "The proportion of correctly classified instances out of the total instances.\n",
      "Accuracy:  35.68 %\n",
      "\n",
      "The ability of the model to avoid false positives.\n",
      "precision:  [42.99732382 65.14285714 24.46463335 30.04587156 25.59012876 36.16751269\n",
      " 33.14659197 56.89981096 39.61290323 59.55414013]\n",
      "\n",
      "The ability of the model to identify all relevant instances.\n",
      "recall:  [48.2 22.8 37.7 26.2 47.7 28.5 35.5 30.1 61.4 18.7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(\"time taken by inbuilt KNN implementation: \", end_time - start_time, \"seconds\")\n",
    "\n",
    "print(\"The proportion of correctly classified instances out of the total instances.\")\n",
    "acc_score = accuracy_score(y_test,knn_prediction)\n",
    "print(\"Accuracy: \", acc_score*100,\"%\")\n",
    "print()\n",
    "\n",
    "print(\"The ability of the model to avoid false positives.\")\n",
    "precision = precision_score(y_test, knn_prediction, average=None)\n",
    "print(\"precision: \", precision*100)\n",
    "print()\n",
    "\n",
    "print(\"The ability of the model to identify all relevant instances.\")\n",
    "recall = recall_score(y_test, knn_prediction, average=None)\n",
    "print(\"recall: \", recall*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d07c5b",
   "metadata": {},
   "source": [
    "#### Preparing sample data for self-implemented KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f801c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_combined = np.concatenate((X_train_flat, X_test_flat), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "df_feature = pd.DataFrame(X_combined)\n",
    "df_label = pd.DataFrame(y_combined)\n",
    "\n",
    "train_combined = pd.concat([df_feature, df_label], ignore_index=True, axis=1)\n",
    "\n",
    "overall_sample_size = 5000\n",
    "stratified_sample = train_combined.groupby(train_combined.iloc[:, -1], group_keys=False).apply(lambda x: x.sample(frac=overall_sample_size/len(train_combined)))\n",
    "stratified_sample.reset_index(drop=True, inplace=True)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test=sklearn.model_selection.train_test_split(stratified_sample,train_size=0.8,test_size=0.2)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "sample_X_train, sample_y_train = train.iloc[:,0:-1], train.iloc[:,-1]\n",
    "sample_X_test, sample_y_test = test.iloc[:,0:-1], test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa8d39",
   "metadata": {},
   "source": [
    "#### self implemented knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b4138bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, X_train, y_train,k=1):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.k = k\n",
    "    \n",
    "    def preprocess(self):\n",
    "        self.X_train_flat = self.X_train.reshape(self.X_train.shape[0], -1)\n",
    "        \n",
    "        self.X_train_standardized = scaler.fit_transform(self.X_train_flat)       \n",
    "        \n",
    "    def train(self):\n",
    "        self.Xtr = self.X_train_standardized\n",
    "        self.Ytr = self.y_train\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        self.X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "        self.X_test_standardized = scaler.fit_transform(self.X_test_flat)   \n",
    "        for i,sample in enumerate(self.X_test_standardized):\n",
    "            dist = np.sqrt(np.sum((self.Xtr - sample)**2, axis=1))\n",
    "            predicted_label = self.y_train[np.argmin(dist)]\n",
    "            y_pred.append(predicted_label)\n",
    "            self.y_pred = y_pred\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    def evaluate(self,y_test):\n",
    "        acc_score = accuracy_score(y_test,self.y_pred)\n",
    "        print(\"Accuracy: \", acc_score)\n",
    "        \n",
    "        precision = precision_score(y_test, self.y_pred, average=None)\n",
    "        print(\"Precision: \", precision*100, \"%\")\n",
    "        \n",
    "        recall = recall_score(y_test, self.y_pred, average=None)\n",
    "        print(\"Recall: \", recall*100,\"%\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22545dc",
   "metadata": {},
   "source": [
    "#### Applying self implemented KNN on CIFAR10 sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d64e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.27\n",
      "Precision:  [36.84210526 36.         21.6        20.48192771 20.2247191  26.5060241\n",
      " 22.95081967 52.63157895 28.57142857 40.90909091] %\n",
      "Recall:  [40.         10.11235955 23.07692308 18.88888889 37.5        22.68041237\n",
      " 26.92307692 19.8019802  60.60606061  8.82352941] %\n",
      "time taken by inbuilt KNN implementation:  86.95178365707397 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "data = KNN(sample_X_train.values, sample_y_train.values)\n",
    "data.preprocess()\n",
    "data.train()\n",
    "data.predict(sample_X_test.values)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "data.evaluate(sample_y_test)\n",
    "print(\"time taken by self implemented KNN: \", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0048eed1",
   "metadata": {},
   "source": [
    "#### Changing euclidean distance to manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "563c0881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "class KNN_L1:\n",
    "    def __init__(self, X_train, y_train,k=1):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.k = k\n",
    "    \n",
    "    def preprocess(self):\n",
    "        self.X_train_flat = self.X_train.reshape(self.X_train.shape[0], -1)\n",
    "        \n",
    "        self.X_train_standardized = scaler.fit_transform(self.X_train_flat)       \n",
    "        \n",
    "    def train(self):\n",
    "        self.Xtr = self.X_train_standardized\n",
    "        self.Ytr = self.y_train\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        self.X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "        self.X_test_standardized = scaler.fit_transform(self.X_test_flat)   \n",
    "        for i,sample in enumerate(self.X_test_standardized):\n",
    "            dist = np.sum(np.abs(self.Xtr - sample), axis=1)\n",
    "            predicted_label = self.y_train[np.argmin(dist)]\n",
    "            y_pred.append(predicted_label)\n",
    "            self.y_pred = y_pred\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    def evaluate(self,y_test):\n",
    "        acc_score = accuracy_score(y_test,self.y_pred)\n",
    "        print(\"Accuracy: \", acc_score)\n",
    "        \n",
    "        precision = precision_score(y_test, self.y_pred, average=None)\n",
    "        print(\"Precision: \", precision*100, \"%\")\n",
    "        \n",
    "        recall = recall_score(y_test, self.y_pred, average=None)\n",
    "        print(\"Recall: \", recall*100,\"%\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d073630",
   "metadata": {},
   "source": [
    "#### Checking accuracy for manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0197b88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.27\n",
      "Precision:  [36.84210526 36.         21.6        20.48192771 20.2247191  26.5060241\n",
      " 22.95081967 52.63157895 28.57142857 40.90909091] %\n",
      "Recall:  [40.         10.11235955 23.07692308 18.88888889 37.5        22.68041237\n",
      " 26.92307692 19.8019802  60.60606061  8.82352941] %\n",
      "time taken by self implemented KNN with Manhattan distance:  76.59070467948914 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "data_L1 = KNN_L1(sample_X_train.values, sample_y_train.values)\n",
    "data_L1.preprocess()\n",
    "data_L1.train()\n",
    "data_L1.predict(sample_X_test.values)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "data.evaluate(sample_y_test)\n",
    "print(\"time taken by self implemented KNN with Manhattan distance: \", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fedb240",
   "metadata": {},
   "source": [
    "#### Improved KNN algorithm using hyperparameter tuning and cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a706a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNN_improved:\n",
    "    def __init__(self, X_train, y_train, k=1):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.k = k\n",
    "        self.scaler_mean = None\n",
    "        self.scaler_std = None\n",
    "    \n",
    "    def preprocess(self):\n",
    "        self.X_train_flat = self.X_train.reshape(self.X_train.shape[0], -1)\n",
    "        \n",
    "        self.scaler_mean = np.mean(self.X_train_flat, axis=0)\n",
    "        self.scaler_std = np.std(self.X_train_flat, axis=0)\n",
    "        self.X_train_standardized = (self.X_train_flat - self.scaler_mean) / self.scaler_std\n",
    "        \n",
    "    def train(self):\n",
    "        self.Xtr = self.X_train_standardized\n",
    "        self.Ytr = self.y_train\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "        X_test_standardized = (X_test_flat - self.scaler_mean) / self.scaler_std\n",
    "\n",
    "        for i, sample in enumerate(X_test_standardized):\n",
    "            dist = np.sum(np.abs(self.Xtr - sample), axis=1)\n",
    "            \n",
    "            k_nearest_indices = np.argsort(dist)[:self.k]\n",
    "            k_nearest_labels = self.y_train[k_nearest_indices]\n",
    "\n",
    "            unique, count = np.unique(k_nearest_labels, return_counts=True)\n",
    "            predicted_label = unique[np.argmax(count)]\n",
    "            y_pred.append(predicted_label)\n",
    "\n",
    "        self.y_pred = np.array(y_pred)\n",
    "        return self.y_pred\n",
    "\n",
    "    def evaluate(self, X, y, n_splits=5):\n",
    "        accuracies = []\n",
    "        \n",
    "        data_size = X.shape[0]\n",
    "        fold_size = data_size // n_splits\n",
    "\n",
    "        for i in range(n_splits):\n",
    "            test_start = i * fold_size\n",
    "            test_end = (i + 1) * fold_size\n",
    "\n",
    "            X_test = X[test_start:test_end]\n",
    "            y_test = y[test_start:test_end]\n",
    "\n",
    "            X_train = np.concatenate((X[:test_start], X[test_end:]), axis=0)\n",
    "            y_train = np.concatenate((y[:test_start], y[test_end:]), axis=0)\n",
    "\n",
    "            self.X_train = X_train\n",
    "            self.y_train = y_train\n",
    "            self.preprocess()\n",
    "            self.train()\n",
    "            self.y_test_pred = self.predict(X_test)\n",
    "\n",
    "            accuracy = np.sum(y_test == self.y_test_pred) / len(y_test)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "            print(f\"Fold Accuracy: {accuracy}\")\n",
    "\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        print(f\"Mean Cross-Validation Accuracy: {mean_accuracy}\")\n",
    "        return mean_accuracy\n",
    "    \n",
    "    def find_best_k(self, X, y, k_values, n_splits=5):\n",
    "        best_k = None\n",
    "        best_accuracy = 0.0\n",
    "\n",
    "        for k in k_values:\n",
    "            self.k = k\n",
    "            mean_cv_accuracy = self.evaluate(X, y, n_splits)\n",
    "\n",
    "            print(f\"Cross-Validation Accuracy for k={k}: {mean_cv_accuracy}\")\n",
    "\n",
    "            if mean_cv_accuracy > best_accuracy:\n",
    "                best_accuracy = mean_cv_accuracy\n",
    "                best_k = k\n",
    "\n",
    "        print(f\"Best k: {best_k}, Best Cross-Validation Accuracy: {best_accuracy}\")\n",
    "        return best_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.265\n",
      "Fold Accuracy: 0.2975\n",
      "Fold Accuracy: 0.24875\n",
      "Fold Accuracy: 0.27375\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "data2 = KNN_improved(sample_X_train.values, sample_y_train.values)\n",
    "data2.find_best_k(sample_X_train.values,sample_y_train.values,[1,3,4,5,7,9])\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"time taken by improved KNN implementation: \", end_time - start_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83ad46",
   "metadata": {},
   "source": [
    "#### Using best k value obtained from improved algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eb0f1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken by improved KNN implementation:  1772.672188282013 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time2 = time.time()\n",
    "\n",
    "data3 = KNN_improved(sample_X_train.values, sample_y_train.values,9)\n",
    "data3.preprocess()\n",
    "data3.train()\n",
    "data3.predict(sample_X_test.values)\n",
    "\n",
    "end_time2 = time.time()\n",
    "print(\"time taken by improved KNN implementation: \",(( end_time - start_time)+( end_time2 - start_time2)), \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df69609d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.900000000000002 %\n"
     ]
    }
   ],
   "source": [
    " print(accuracy_score(sample_y_test, data3.y_pred)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f1866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
