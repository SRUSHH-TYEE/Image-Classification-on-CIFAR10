{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac8e378",
   "metadata": {},
   "source": [
    "## Srushti Nayak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41651a80",
   "metadata": {},
   "source": [
    "### Assignment 4: CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40a35c",
   "metadata": {},
   "source": [
    "#### Importing required libraries and loading CIFAR10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f1166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1bad31",
   "metadata": {},
   "source": [
    "#### CNN with SGD + Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e8fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_SGD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_SGD, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "        for epoch in range(10):  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b330f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.302\n",
      "[1,   400] loss: 2.297\n",
      "[1,   600] loss: 2.288\n",
      "[2,   200] loss: 2.159\n",
      "[2,   400] loss: 2.063\n",
      "[2,   600] loss: 2.000\n",
      "[3,   200] loss: 1.923\n",
      "[3,   400] loss: 1.882\n",
      "[3,   600] loss: 1.842\n",
      "[4,   200] loss: 1.770\n",
      "[4,   400] loss: 1.725\n",
      "[4,   600] loss: 1.704\n",
      "[5,   200] loss: 1.635\n",
      "[5,   400] loss: 1.608\n",
      "[5,   600] loss: 1.586\n",
      "[6,   200] loss: 1.547\n",
      "[6,   400] loss: 1.539\n",
      "[6,   600] loss: 1.508\n",
      "[7,   200] loss: 1.486\n",
      "[7,   400] loss: 1.478\n",
      "[7,   600] loss: 1.455\n",
      "[8,   200] loss: 1.412\n",
      "[8,   400] loss: 1.427\n",
      "[8,   600] loss: 1.409\n",
      "[9,   200] loss: 1.377\n",
      "[9,   400] loss: 1.357\n",
      "[9,   600] loss: 1.366\n",
      "[10,   200] loss: 1.316\n",
      "[10,   400] loss: 1.321\n",
      "[10,   600] loss: 1.294\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 56 %\n"
     ]
    }
   ],
   "source": [
    "CNN_SGD_obj = CNN_SGD()\n",
    "CNN_SGD_obj.train(trainloader)\n",
    "CNN_SGD_obj.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599e0766",
   "metadata": {},
   "source": [
    "#### CNN with SGD without momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f439bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_SGD_NO_MOM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_SGD_NO_MOM, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(self.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(10):  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22776023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.302\n",
      "[1,   400] loss: 2.301\n",
      "[1,   600] loss: 2.301\n",
      "[2,   200] loss: 2.300\n",
      "[2,   400] loss: 2.299\n",
      "[2,   600] loss: 2.298\n",
      "[3,   200] loss: 2.297\n",
      "[3,   400] loss: 2.296\n",
      "[3,   600] loss: 2.295\n",
      "[4,   200] loss: 2.294\n",
      "[4,   400] loss: 2.292\n",
      "[4,   600] loss: 2.292\n",
      "[5,   200] loss: 2.289\n",
      "[5,   400] loss: 2.287\n",
      "[5,   600] loss: 2.286\n",
      "[6,   200] loss: 2.281\n",
      "[6,   400] loss: 2.280\n",
      "[6,   600] loss: 2.277\n",
      "[7,   200] loss: 2.270\n",
      "[7,   400] loss: 2.266\n",
      "[7,   600] loss: 2.260\n",
      "[8,   200] loss: 2.248\n",
      "[8,   400] loss: 2.238\n",
      "[8,   600] loss: 2.229\n",
      "[9,   200] loss: 2.204\n",
      "[9,   400] loss: 2.187\n",
      "[9,   600] loss: 2.173\n",
      "[10,   200] loss: 2.144\n",
      "[10,   400] loss: 2.127\n",
      "[10,   600] loss: 2.115\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 26 %\n"
     ]
    }
   ],
   "source": [
    "CNN_SGD__NO_MOM_obj = CNN_SGD_NO_MOM()\n",
    "CNN_SGD__NO_MOM_obj.train(trainloader)\n",
    "CNN_SGD__NO_MOM_obj.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b88094",
   "metadata": {},
   "source": [
    "#### CNN with ADAgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7a04914",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_ADA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ADA, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adagrad(self.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(10):  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b025f2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 1.968\n",
      "[1,   400] loss: 1.777\n",
      "[1,   600] loss: 1.710\n",
      "[2,   200] loss: 1.638\n",
      "[2,   400] loss: 1.617\n",
      "[2,   600] loss: 1.581\n",
      "[3,   200] loss: 1.567\n",
      "[3,   400] loss: 1.534\n",
      "[3,   600] loss: 1.540\n",
      "[4,   200] loss: 1.524\n",
      "[4,   400] loss: 1.502\n",
      "[4,   600] loss: 1.505\n",
      "[5,   200] loss: 1.498\n",
      "[5,   400] loss: 1.493\n",
      "[5,   600] loss: 1.481\n",
      "[6,   200] loss: 1.487\n",
      "[6,   400] loss: 1.483\n",
      "[6,   600] loss: 1.460\n",
      "[7,   200] loss: 1.456\n",
      "[7,   400] loss: 1.459\n",
      "[7,   600] loss: 1.450\n",
      "[8,   200] loss: 1.448\n",
      "[8,   400] loss: 1.452\n",
      "[8,   600] loss: 1.439\n",
      "[9,   200] loss: 1.430\n",
      "[9,   400] loss: 1.439\n",
      "[9,   600] loss: 1.430\n",
      "[10,   200] loss: 1.428\n",
      "[10,   400] loss: 1.412\n",
      "[10,   600] loss: 1.423\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 51 %\n"
     ]
    }
   ],
   "source": [
    "CNN_ADA_obj = CNN_ADA()\n",
    "CNN_ADA_obj.train(trainloader)\n",
    "CNN_ADA_obj.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e55839f",
   "metadata": {},
   "source": [
    "#### CNN with RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a1184d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_RMS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_RMS, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.RMSprop(self.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(10):  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd869120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.020\n",
      "[1,   400] loss: 1.659\n",
      "[1,   600] loss: 1.532\n",
      "[2,   200] loss: 1.336\n",
      "[2,   400] loss: 1.274\n",
      "[2,   600] loss: 1.206\n",
      "[3,   200] loss: 1.078\n",
      "[3,   400] loss: 1.044\n",
      "[3,   600] loss: 1.013\n",
      "[4,   200] loss: 0.926\n",
      "[4,   400] loss: 0.919\n",
      "[4,   600] loss: 0.890\n",
      "[5,   200] loss: 0.840\n",
      "[5,   400] loss: 0.824\n",
      "[5,   600] loss: 0.820\n",
      "[6,   200] loss: 0.757\n",
      "[6,   400] loss: 0.769\n",
      "[6,   600] loss: 0.756\n",
      "[7,   200] loss: 0.729\n",
      "[7,   400] loss: 0.713\n",
      "[7,   600] loss: 0.701\n",
      "[8,   200] loss: 0.685\n",
      "[8,   400] loss: 0.665\n",
      "[8,   600] loss: 0.667\n",
      "[9,   200] loss: 0.643\n",
      "[9,   400] loss: 0.649\n",
      "[9,   600] loss: 0.651\n",
      "[10,   200] loss: 0.619\n",
      "[10,   400] loss: 0.615\n",
      "[10,   600] loss: 0.618\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 65 %\n"
     ]
    }
   ],
   "source": [
    "CNN_RMSProp_obj = CNN_RMS()\n",
    "CNN_RMSProp_obj.train(trainloader)\n",
    "CNN_RMSProp_obj.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd041aa2",
   "metadata": {},
   "source": [
    "#### CNN with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34fc4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_ADAM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ADAM, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(10):  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "941c3c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 1.856\n",
      "[1,   400] loss: 1.525\n",
      "[1,   600] loss: 1.388\n",
      "[2,   200] loss: 1.231\n",
      "[2,   400] loss: 1.149\n",
      "[2,   600] loss: 1.094\n",
      "[3,   200] loss: 0.991\n",
      "[3,   400] loss: 0.966\n",
      "[3,   600] loss: 0.934\n",
      "[4,   200] loss: 0.874\n",
      "[4,   400] loss: 0.864\n",
      "[4,   600] loss: 0.854\n",
      "[5,   200] loss: 0.787\n",
      "[5,   400] loss: 0.771\n",
      "[5,   600] loss: 0.786\n",
      "[6,   200] loss: 0.739\n",
      "[6,   400] loss: 0.728\n",
      "[6,   600] loss: 0.723\n",
      "[7,   200] loss: 0.685\n",
      "[7,   400] loss: 0.689\n",
      "[7,   600] loss: 0.697\n",
      "[8,   200] loss: 0.644\n",
      "[8,   400] loss: 0.646\n",
      "[8,   600] loss: 0.643\n",
      "[9,   200] loss: 0.638\n",
      "[9,   400] loss: 0.626\n",
      "[9,   600] loss: 0.614\n",
      "[10,   200] loss: 0.588\n",
      "[10,   400] loss: 0.588\n",
      "[10,   600] loss: 0.597\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 78 %\n"
     ]
    }
   ],
   "source": [
    "CNN_Adem_obj = CNN_ADAM()\n",
    "CNN_Adem_obj.train(trainloader)\n",
    "CNN_Adem_obj.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b798b31",
   "metadata": {},
   "source": [
    "#### RMSProp with l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f97fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_RMS_Reg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_RMS_Reg, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.RMSprop(self.parameters(), lr=0.001, weight_decay=0.001)  \n",
    "\n",
    "        for epoch in range(10):  \n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72b958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.004\n",
      "[1,   400] loss: 1.676\n",
      "[1,   600] loss: 1.554\n",
      "[2,   200] loss: 1.394\n",
      "[2,   400] loss: 1.341\n",
      "[2,   600] loss: 1.292\n",
      "[3,   200] loss: 1.214\n",
      "[3,   400] loss: 1.173\n",
      "[3,   600] loss: 1.142\n",
      "[4,   200] loss: 1.075\n",
      "[4,   400] loss: 1.072\n",
      "[4,   600] loss: 1.051\n",
      "[5,   200] loss: 1.006\n",
      "[5,   400] loss: 0.986\n",
      "[5,   600] loss: 0.977\n",
      "[6,   200] loss: 0.939\n",
      "[6,   400] loss: 0.941\n",
      "[6,   600] loss: 0.908\n",
      "[7,   200] loss: 0.876\n",
      "[7,   400] loss: 0.883\n",
      "[7,   600] loss: 0.882\n",
      "[8,   200] loss: 0.846\n",
      "[8,   400] loss: 0.844\n",
      "[8,   600] loss: 0.849\n",
      "[9,   200] loss: 0.815\n",
      "[9,   400] loss: 0.810\n",
      "[9,   600] loss: 0.820\n",
      "[10,   200] loss: 0.802\n",
      "[10,   400] loss: 0.786\n",
      "[10,   600] loss: 0.777\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 65 %\n"
     ]
    }
   ],
   "source": [
    "CNN_RMS_Reg_obj = CNN_RMS_Reg()\n",
    "CNN_RMS_Reg_obj.train(trainloader)\n",
    "CNN_RMS_Reg_obj.test(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c8cdf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_ADAM_Reg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ADAM_Reg, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001, weight_decay=0.001)  \n",
    "\n",
    "        for epoch in range(10):  \n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e7eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 1.877\n",
      "[1,   400] loss: 1.561\n",
      "[1,   600] loss: 1.435\n",
      "[2,   200] loss: 1.291\n",
      "[2,   400] loss: 1.204\n",
      "[2,   600] loss: 1.147\n",
      "[3,   200] loss: 1.063\n",
      "[3,   400] loss: 1.027\n",
      "[3,   600] loss: 0.991\n",
      "[4,   200] loss: 0.937\n",
      "[4,   400] loss: 0.921\n",
      "[4,   600] loss: 0.919\n",
      "[5,   200] loss: 0.876\n",
      "[5,   400] loss: 0.851\n",
      "[5,   600] loss: 0.850\n",
      "[6,   200] loss: 0.820\n",
      "[6,   400] loss: 0.810\n",
      "[6,   600] loss: 0.813\n",
      "[7,   200] loss: 0.792\n",
      "[7,   400] loss: 0.797\n",
      "[7,   600] loss: 0.771\n",
      "[8,   200] loss: 0.773\n",
      "[8,   400] loss: 0.736\n",
      "[8,   600] loss: 0.761\n",
      "[9,   200] loss: 0.725\n",
      "[9,   400] loss: 0.734\n",
      "[9,   600] loss: 0.732\n",
      "[10,   200] loss: 0.711\n",
      "[10,   400] loss: 0.710\n",
      "[10,   600] loss: 0.729\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 76 %\n"
     ]
    }
   ],
   "source": [
    "CNN_ADAM_Reg_obj = CNN_ADAM_Reg()\n",
    "CNN_ADAM_Reg_obj.train(trainloader)\n",
    "CNN_ADAM_Reg_obj.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9825876",
   "metadata": {},
   "source": [
    "#### Batch normalization with RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5505d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_RMS_BNORM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_RMS_BNORM, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)  \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  \n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  \n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.RMSprop(self.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(10):  \n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b3d61e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.196\n",
      "[1,   400] loss: 1.549\n",
      "[1,   600] loss: 1.392\n",
      "[2,   200] loss: 1.189\n",
      "[2,   400] loss: 1.139\n",
      "[2,   600] loss: 1.071\n",
      "[3,   200] loss: 0.999\n",
      "[3,   400] loss: 0.971\n",
      "[3,   600] loss: 0.949\n",
      "[4,   200] loss: 0.896\n",
      "[4,   400] loss: 0.891\n",
      "[4,   600] loss: 0.858\n",
      "[5,   200] loss: 0.818\n",
      "[5,   400] loss: 0.815\n",
      "[5,   600] loss: 0.806\n",
      "[6,   200] loss: 0.770\n",
      "[6,   400] loss: 0.773\n",
      "[6,   600] loss: 0.771\n",
      "[7,   200] loss: 0.734\n",
      "[7,   400] loss: 0.729\n",
      "[7,   600] loss: 0.732\n",
      "[8,   200] loss: 0.683\n",
      "[8,   400] loss: 0.688\n",
      "[8,   600] loss: 0.703\n",
      "[9,   200] loss: 0.650\n",
      "[9,   400] loss: 0.675\n",
      "[9,   600] loss: 0.663\n",
      "[10,   200] loss: 0.636\n",
      "[10,   400] loss: 0.638\n",
      "[10,   600] loss: 0.638\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 75 %\n"
     ]
    }
   ],
   "source": [
    "CNN_RMS_BNORM_obj = CNN_RMS_BNORM()\n",
    "CNN_RMS_BNORM_obj.train(trainloader)\n",
    "CNN_RMS_BNORM_obj.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecb9ffc",
   "metadata": {},
   "source": [
    "#### Batch normalization with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b487fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_ADAM_BNORM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ADAM_BNORM, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)  \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  \n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x)))) \n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(10):  \n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77b71a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 1.753\n",
      "[1,   400] loss: 1.421\n",
      "[1,   600] loss: 1.289\n",
      "[2,   200] loss: 1.096\n",
      "[2,   400] loss: 1.034\n",
      "[2,   600] loss: 1.011\n",
      "[3,   200] loss: 0.918\n",
      "[3,   400] loss: 0.897\n",
      "[3,   600] loss: 0.890\n",
      "[4,   200] loss: 0.826\n",
      "[4,   400] loss: 0.820\n",
      "[4,   600] loss: 0.811\n",
      "[5,   200] loss: 0.755\n",
      "[5,   400] loss: 0.761\n",
      "[5,   600] loss: 0.738\n",
      "[6,   200] loss: 0.689\n",
      "[6,   400] loss: 0.711\n",
      "[6,   600] loss: 0.698\n",
      "[7,   200] loss: 0.670\n",
      "[7,   400] loss: 0.662\n",
      "[7,   600] loss: 0.667\n",
      "[8,   200] loss: 0.652\n",
      "[8,   400] loss: 0.648\n",
      "[8,   600] loss: 0.624\n",
      "[9,   200] loss: 0.604\n",
      "[9,   400] loss: 0.607\n",
      "[9,   600] loss: 0.630\n",
      "[10,   200] loss: 0.598\n",
      "[10,   400] loss: 0.592\n",
      "[10,   600] loss: 0.580\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 78 %\n"
     ]
    }
   ],
   "source": [
    "CNN_ADAM_BNORM_obj = CNN_ADAM_BNORM()\n",
    "CNN_ADAM_BNORM_obj.train(trainloader)\n",
    "CNN_ADAM_BNORM_obj.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3bcb2f",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning in adem optimizer and RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c302d95e",
   "metadata": {},
   "source": [
    "#### RMSProp with batch normalization, increasing epoches and learning rate. epoches =  15, learning rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40b6b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_RMS_BNORM2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_RMS_BNORM2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)  \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  \n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  \n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.RMSprop(self.parameters(), lr=0.005)\n",
    "\n",
    "        for epoch in range(15):  \n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "306888d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 7.638\n",
      "[1,   400] loss: 2.053\n",
      "[1,   600] loss: 1.891\n",
      "[2,   200] loss: 1.599\n",
      "[2,   400] loss: 1.482\n",
      "[2,   600] loss: 1.389\n",
      "[3,   200] loss: 1.244\n",
      "[3,   400] loss: 1.194\n",
      "[3,   600] loss: 1.134\n",
      "[4,   200] loss: 1.072\n",
      "[4,   400] loss: 1.024\n",
      "[4,   600] loss: 0.987\n",
      "[5,   200] loss: 0.939\n",
      "[5,   400] loss: 0.919\n",
      "[5,   600] loss: 0.887\n",
      "[6,   200] loss: 0.845\n",
      "[6,   400] loss: 0.834\n",
      "[6,   600] loss: 0.819\n",
      "[7,   200] loss: 0.805\n",
      "[7,   400] loss: 0.790\n",
      "[7,   600] loss: 0.769\n",
      "[8,   200] loss: 0.753\n",
      "[8,   400] loss: 0.750\n",
      "[8,   600] loss: 0.735\n",
      "[9,   200] loss: 0.704\n",
      "[9,   400] loss: 0.713\n",
      "[9,   600] loss: 0.706\n",
      "[10,   200] loss: 0.668\n",
      "[10,   400] loss: 0.686\n",
      "[10,   600] loss: 0.697\n",
      "[11,   200] loss: 0.661\n",
      "[11,   400] loss: 0.663\n",
      "[11,   600] loss: 0.668\n",
      "[12,   200] loss: 0.636\n",
      "[12,   400] loss: 0.632\n",
      "[12,   600] loss: 0.634\n",
      "[13,   200] loss: 0.616\n",
      "[13,   400] loss: 0.613\n",
      "[13,   600] loss: 0.624\n",
      "[14,   200] loss: 0.617\n",
      "[14,   400] loss: 0.594\n",
      "[14,   600] loss: 0.609\n",
      "[15,   200] loss: 0.584\n",
      "[15,   400] loss: 0.578\n",
      "[15,   600] loss: 0.597\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 77 %\n"
     ]
    }
   ],
   "source": [
    "CNN_RMS_BNORM_obj2 = CNN_RMS_BNORM2()\n",
    "CNN_RMS_BNORM_obj2.train(trainloader)\n",
    "CNN_RMS_BNORM_obj2.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c109b14",
   "metadata": {},
   "source": [
    "#### Adem, increasing epoches and learning rate. epoches =  15, learning rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49578e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_ADAM2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ADAM2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.005)\n",
    "\n",
    "        for epoch in range(15):  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199: \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a77a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 1.963\n",
      "[1,   400] loss: 1.689\n",
      "[1,   600] loss: 1.577\n",
      "[2,   200] loss: 1.506\n",
      "[2,   400] loss: 1.441\n",
      "[2,   600] loss: 1.422\n",
      "[3,   200] loss: 1.358\n",
      "[3,   400] loss: 1.360\n",
      "[3,   600] loss: 1.345\n",
      "[4,   200] loss: 1.337\n",
      "[4,   400] loss: 1.307\n",
      "[4,   600] loss: 1.295\n",
      "[5,   200] loss: 1.260\n",
      "[5,   400] loss: 1.269\n",
      "[5,   600] loss: 1.249\n",
      "[6,   200] loss: 1.241\n",
      "[6,   400] loss: 1.242\n",
      "[6,   600] loss: 1.218\n",
      "[7,   200] loss: 1.208\n",
      "[7,   400] loss: 1.194\n",
      "[7,   600] loss: 1.220\n",
      "[8,   200] loss: 1.204\n",
      "[8,   400] loss: 1.189\n",
      "[8,   600] loss: 1.181\n",
      "[9,   200] loss: 1.204\n",
      "[9,   400] loss: 1.176\n",
      "[9,   600] loss: 1.175\n",
      "[10,   200] loss: 1.172\n",
      "[10,   400] loss: 1.190\n",
      "[10,   600] loss: 1.163\n",
      "[11,   200] loss: 1.146\n",
      "[11,   400] loss: 1.196\n",
      "[11,   600] loss: 1.141\n",
      "[12,   200] loss: 1.155\n",
      "[12,   400] loss: 1.159\n",
      "[12,   600] loss: 1.152\n",
      "[13,   200] loss: 1.142\n",
      "[13,   400] loss: 1.163\n",
      "[13,   600] loss: 1.172\n",
      "[14,   200] loss: 1.130\n",
      "[14,   400] loss: 1.137\n",
      "[14,   600] loss: 1.153\n",
      "[15,   200] loss: 1.136\n",
      "[15,   400] loss: 1.129\n",
      "[15,   600] loss: 1.150\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 61 %\n"
     ]
    }
   ],
   "source": [
    "CNN_Adem2_obj = CNN_ADAM2()\n",
    "CNN_Adem2_obj.train(trainloader)\n",
    "CNN_Adem2_obj.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea5d901",
   "metadata": {},
   "source": [
    "#### RMSProp with only increased epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fec658fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_RMS_BNORM3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_RMS_BNORM3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)  \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  \n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  \n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.RMSprop(self.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(15):  \n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2a0efb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.333\n",
      "[1,   400] loss: 1.530\n",
      "[1,   600] loss: 1.402\n",
      "[2,   200] loss: 1.211\n",
      "[2,   400] loss: 1.133\n",
      "[2,   600] loss: 1.085\n",
      "[3,   200] loss: 0.999\n",
      "[3,   400] loss: 0.965\n",
      "[3,   600] loss: 0.952\n",
      "[4,   200] loss: 0.896\n",
      "[4,   400] loss: 0.884\n",
      "[4,   600] loss: 0.855\n",
      "[5,   200] loss: 0.826\n",
      "[5,   400] loss: 0.811\n",
      "[5,   600] loss: 0.797\n",
      "[6,   200] loss: 0.774\n",
      "[6,   400] loss: 0.762\n",
      "[6,   600] loss: 0.754\n",
      "[7,   200] loss: 0.719\n",
      "[7,   400] loss: 0.720\n",
      "[7,   600] loss: 0.711\n",
      "[8,   200] loss: 0.680\n",
      "[8,   400] loss: 0.687\n",
      "[8,   600] loss: 0.690\n",
      "[9,   200] loss: 0.670\n",
      "[9,   400] loss: 0.653\n",
      "[9,   600] loss: 0.659\n",
      "[10,   200] loss: 0.627\n",
      "[10,   400] loss: 0.627\n",
      "[10,   600] loss: 0.643\n",
      "[11,   200] loss: 0.607\n",
      "[11,   400] loss: 0.608\n",
      "[11,   600] loss: 0.618\n",
      "[12,   200] loss: 0.588\n",
      "[12,   400] loss: 0.577\n",
      "[12,   600] loss: 0.597\n",
      "[13,   200] loss: 0.567\n",
      "[13,   400] loss: 0.581\n",
      "[13,   600] loss: 0.570\n",
      "[14,   200] loss: 0.548\n",
      "[14,   400] loss: 0.550\n",
      "[14,   600] loss: 0.564\n",
      "[15,   200] loss: 0.527\n",
      "[15,   400] loss: 0.536\n",
      "[15,   600] loss: 0.534\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 77 %\n"
     ]
    }
   ],
   "source": [
    "CNN_RMS_BNORM3_obj = CNN_RMS_BNORM3()\n",
    "CNN_RMS_BNORM3_obj.train(trainloader)\n",
    "CNN_RMS_BNORM3_obj.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539a293",
   "metadata": {},
   "source": [
    "#### Adem with only increased epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "050c241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_ADAM3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ADAM3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, trainloader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(15):  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199:  \n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 200))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (\n",
    "            100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc90be9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 1.863\n",
      "[1,   400] loss: 1.531\n",
      "[1,   600] loss: 1.431\n",
      "[2,   200] loss: 1.239\n",
      "[2,   400] loss: 1.162\n",
      "[2,   600] loss: 1.093\n",
      "[3,   200] loss: 1.002\n",
      "[3,   400] loss: 0.961\n",
      "[3,   600] loss: 0.936\n",
      "[4,   200] loss: 0.866\n",
      "[4,   400] loss: 0.854\n",
      "[4,   600] loss: 0.842\n",
      "[5,   200] loss: 0.792\n",
      "[5,   400] loss: 0.778\n",
      "[5,   600] loss: 0.777\n",
      "[6,   200] loss: 0.727\n",
      "[6,   400] loss: 0.719\n",
      "[6,   600] loss: 0.723\n",
      "[7,   200] loss: 0.674\n",
      "[7,   400] loss: 0.689\n",
      "[7,   600] loss: 0.678\n",
      "[8,   200] loss: 0.650\n",
      "[8,   400] loss: 0.661\n",
      "[8,   600] loss: 0.624\n",
      "[9,   200] loss: 0.614\n",
      "[9,   400] loss: 0.629\n",
      "[9,   600] loss: 0.612\n",
      "[10,   200] loss: 0.581\n",
      "[10,   400] loss: 0.599\n",
      "[10,   600] loss: 0.596\n",
      "[11,   200] loss: 0.569\n",
      "[11,   400] loss: 0.587\n",
      "[11,   600] loss: 0.587\n",
      "[12,   200] loss: 0.539\n",
      "[12,   400] loss: 0.543\n",
      "[12,   600] loss: 0.556\n",
      "[13,   200] loss: 0.533\n",
      "[13,   400] loss: 0.543\n",
      "[13,   600] loss: 0.542\n",
      "[14,   200] loss: 0.510\n",
      "[14,   400] loss: 0.527\n",
      "[14,   600] loss: 0.511\n",
      "[15,   200] loss: 0.491\n",
      "[15,   400] loss: 0.501\n",
      "[15,   600] loss: 0.514\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 80 %\n"
     ]
    }
   ],
   "source": [
    "CNN_Adem3_obj = CNN_ADAM3()\n",
    "CNN_Adem3_obj.train(trainloader)\n",
    "CNN_Adem3_obj.test(testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
